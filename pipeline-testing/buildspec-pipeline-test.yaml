version: 0.2

phases:
  install:
    runtime-versions:
      docker: 19
    commands:
      # Various CFN resources and exports use these prefixes to ensure uniqueness.
      # Prefix for test infra
      - PREFIX=zzz-a-new-startup-test-ecs
      # Prefix of what we are testing
      - TARGET_PREFIX=a-new-startup-ecs
      
      # Gotta install AWS CLI v2
      - pip3 uninstall awscli -y
      - curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
      - unzip awscliv2.zip 1> /dev/null
      - ./aws/install
      - aws --version
      
      - curl --version

  pre_build:
    commands:
    
      # NOTE: The pipeline should have a stage that creates the $PREFIX-infra stack before this CodeBuild project is invoked.
      # This is where the Bucket and Subnets come from ...
      
      # Grab some Stack Exports
      - BUCKET_NAME=$(aws cloudformation list-exports --query "Exports[?Name=='$PREFIX-CodeBucket'].Value" --output text)
      - echo "BUCKET_NAME=$BUCKET_NAME."
      - PUBLIC_SUBNETS=$(aws cloudformation list-exports --query "Exports[?Name=='$PREFIX-PublicSubnetIds'].Value" --output text)
      - echo "PUBLIC_SUBNETS=$PUBLIC_SUBNETS."
      
      # Get Private Key - from SecretsManager. It MUST be in a Secret named as "github-pipeline-private-key-1"
      - KEY_NAME=github-pipeline-private-key-1
      - SECRET_ARN=$(aws secretsmanager describe-secret --secret-id $KEY_NAME --query "ARN" --output text)
      
      # Retrieve that value, decode from base64, and write it to ~/.ssh
      - mkdir -p ~/.ssh
      - aws secretsmanager get-secret-value --secret-id "$SECRET_ARN" --query "SecretString" --output text | jq -r '.privatekeybase64' | base64 -d > ~/.ssh/github_pipeline
      
      # Update the ~/.ssh/config so we use it automatically when working with Github.
      # The Github repo is the source of this pipeline, but there's a DIFFERENT Github repo (the a-new-startup application code)
      # that we have to access directly - which is why we need this key.  See ./01-repo.sh ...
      - printf '%s\n%s\n' "Host github.com" "IdentityFile ~/.ssh/github_pipeline" >> ~/.ssh/config
      - cat ~/.ssh/config
      - chmod 600 ~/.ssh/github_pipeline
      
  build:
    commands:
      # Run the install
      - ./install.sh "$BUCKET_NAME" "$PUBLIC_SUBNETS"
     
      # The initial pipeline run may still be going... wait for a 2nd exectuion
      
      # Release latest change in the pipeline and wait for it to complete via this helper script
      # Wait up to 20 minutes for it to complete.
      - ./96-release-change.sh "a-new-startup-ecs-containerized" 20
      
      # Wait until ALB Provisioned
      - ALB_ARN=$(aws cloudformation list-exports --query "Exports[?Name=='$TARGET_PREFIX-LoadBalancer'].Value" --output text)
      - echo "ALB_ARN=$ALB_ARN."
      - aws elbv2 wait load-balancer-available --load-balancer-arns $ALB_ARN 
      - ALB_DNS=$(aws cloudformation list-exports --query "Exports[?Name=='$TARGET_PREFIX-LoadBalancerDNSName'].Value" --output text)
      - echo "ALB_DNS=$ALB_DNS."
      # NOTE: http://
      - curl "http://$ALB_DNS" >> report.txt
      - echo $?
      
  post_build:
    commands:
    
      # After all that , we wipe things clean back to where we started.
      # (It is a CI/CD Pipeline, after all)
      - ./99-uninstall.sh --yes
      
      # Count the number of stacks remaining that start with "a-new-startup-ecs-"
      # If > 0 , assume uninstall failed.
      - NUM_STACKS_REMAINING=$(aws cloudformation describe-stacks --query "Stacks[].StackName" | grep '"a-new-startup-ecs-' | wc -l)
      - if [[ $NUM_STACKS_REMAINING -ne 0 ]]; then echo "There are stacks remaining - it looks like uninstall failed."; exit 6; fi
      
      # We need to empty the temporary code bucket before we try and delete the infra stack...
      - CODE_BUCKET=$(aws cloudformation list-exports --query "Exports[?Name=='$PREFIX-CodeBucket'].Value" --output text )
      - echo "Will empty CODE_BUCKET=$CODE_BUCKET."

      # Empty the artifacts bucket (Otherwise stack delete will fail)
      - aws s3 rm s3://$CODE_BUCKET --recursive

      # Delete even the VPC we used. It will be re-created next run.
      - aws cloudformation delete-stack --stack-name "$PREFIX-infra"
      - aws cloudformation wait stack-delete-complete --stack-name "$PREFIX-infra"
      
artifacts:
  files:
    - report.txt 
